{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting the working directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/shovonsengupta/Desktop/Python/Notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shovonsengupta/Desktop/Python/Notebook\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-class Classification Model using Keras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the relevant Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger,ModelCheckpoint\n",
    "csv_logger = CSVLogger('mlevel_logfile.log', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Printing first digit\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (\"\\nPrinting fourth digit\")\n",
    "plt.matshow(digits.images[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 64\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars_stdscle = StandardScaler().fit_transform(X)\n",
    "y_ = np.zeros((np.shape(y)[0],num_classes))\n",
    "y_[np.arange(np.shape(y)[0]),y]=1\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_vars_stdscle,y_,train_size = 0.7,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN_Multi_Classification_KS(_input_dim):\n",
    "    # Layer 1\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10,input_shape=(_input_dim,)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Layer 2\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "    # Layer 3\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    adam_opt = Adam(lr=0.01)\n",
    "    # Model compilation\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=adam_opt)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 870\n",
      "Trainable params: 870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = DNN_Multi_Classification_KS(input_dim)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 50\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model at each iteration and logging the loss into logger on runtime using list\n",
    "file_name = 'weights-improvement-{epoch:02d}.hdf5'\n",
    "checkpoint = ModelCheckpoint(file_name, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.72985, saving model to weights-improvement-01.hdf5\n",
      "38/38 - 0s - loss: 1.7298 - val_loss: 1.2738\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: loss improved from 1.72985 to 0.79467, saving model to weights-improvement-02.hdf5\n",
      "38/38 - 0s - loss: 0.7947 - val_loss: 0.7201\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: loss improved from 0.79467 to 0.39966, saving model to weights-improvement-03.hdf5\n",
      "38/38 - 0s - loss: 0.3997 - val_loss: 0.4031\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: loss improved from 0.39966 to 0.22522, saving model to weights-improvement-04.hdf5\n",
      "38/38 - 0s - loss: 0.2252 - val_loss: 0.4989\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: loss improved from 0.22522 to 0.15764, saving model to weights-improvement-05.hdf5\n",
      "38/38 - 0s - loss: 0.1576 - val_loss: 0.4595\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: loss improved from 0.15764 to 0.11062, saving model to weights-improvement-06.hdf5\n",
      "38/38 - 0s - loss: 0.1106 - val_loss: 0.3925\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: loss improved from 0.11062 to 0.07864, saving model to weights-improvement-07.hdf5\n",
      "38/38 - 0s - loss: 0.0786 - val_loss: 0.4172\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: loss improved from 0.07864 to 0.05319, saving model to weights-improvement-08.hdf5\n",
      "38/38 - 0s - loss: 0.0532 - val_loss: 0.3594\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: loss improved from 0.05319 to 0.04664, saving model to weights-improvement-09.hdf5\n",
      "38/38 - 0s - loss: 0.0466 - val_loss: 0.3709\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: loss improved from 0.04664 to 0.03614, saving model to weights-improvement-10.hdf5\n",
      "38/38 - 0s - loss: 0.0361 - val_loss: 0.3139\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: loss improved from 0.03614 to 0.02481, saving model to weights-improvement-11.hdf5\n",
      "38/38 - 0s - loss: 0.0248 - val_loss: 0.3845\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: loss improved from 0.02481 to 0.01999, saving model to weights-improvement-12.hdf5\n",
      "38/38 - 0s - loss: 0.0200 - val_loss: 0.3612\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: loss improved from 0.01999 to 0.01557, saving model to weights-improvement-13.hdf5\n",
      "38/38 - 0s - loss: 0.0156 - val_loss: 0.3019\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: loss improved from 0.01557 to 0.01159, saving model to weights-improvement-14.hdf5\n",
      "38/38 - 0s - loss: 0.0116 - val_loss: 0.3519\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: loss improved from 0.01159 to 0.00951, saving model to weights-improvement-15.hdf5\n",
      "38/38 - 0s - loss: 0.0095 - val_loss: 0.3491\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: loss improved from 0.00951 to 0.00774, saving model to weights-improvement-16.hdf5\n",
      "38/38 - 0s - loss: 0.0077 - val_loss: 0.3663\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: loss improved from 0.00774 to 0.00726, saving model to weights-improvement-17.hdf5\n",
      "38/38 - 0s - loss: 0.0073 - val_loss: 0.3519\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: loss improved from 0.00726 to 0.00624, saving model to weights-improvement-18.hdf5\n",
      "38/38 - 0s - loss: 0.0062 - val_loss: 0.3788\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: loss improved from 0.00624 to 0.00576, saving model to weights-improvement-19.hdf5\n",
      "38/38 - 0s - loss: 0.0058 - val_loss: 0.3644\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: loss improved from 0.00576 to 0.00533, saving model to weights-improvement-20.hdf5\n",
      "38/38 - 0s - loss: 0.0053 - val_loss: 0.3893\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: loss improved from 0.00533 to 0.00466, saving model to weights-improvement-21.hdf5\n",
      "38/38 - 0s - loss: 0.0047 - val_loss: 0.3899\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: loss improved from 0.00466 to 0.00400, saving model to weights-improvement-22.hdf5\n",
      "38/38 - 0s - loss: 0.0040 - val_loss: 0.3928\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: loss improved from 0.00400 to 0.00388, saving model to weights-improvement-23.hdf5\n",
      "38/38 - 0s - loss: 0.0039 - val_loss: 0.4052\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: loss improved from 0.00388 to 0.00322, saving model to weights-improvement-24.hdf5\n",
      "38/38 - 0s - loss: 0.0032 - val_loss: 0.4236\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: loss improved from 0.00322 to 0.00313, saving model to weights-improvement-25.hdf5\n",
      "38/38 - 0s - loss: 0.0031 - val_loss: 0.4137\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: loss improved from 0.00313 to 0.00287, saving model to weights-improvement-26.hdf5\n",
      "38/38 - 0s - loss: 0.0029 - val_loss: 0.4360\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: loss improved from 0.00287 to 0.00265, saving model to weights-improvement-27.hdf5\n",
      "38/38 - 0s - loss: 0.0026 - val_loss: 0.4059\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: loss improved from 0.00265 to 0.00253, saving model to weights-improvement-28.hdf5\n",
      "38/38 - 0s - loss: 0.0025 - val_loss: 0.4422\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: loss improved from 0.00253 to 0.00200, saving model to weights-improvement-29.hdf5\n",
      "38/38 - 0s - loss: 0.0020 - val_loss: 0.4330\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: loss improved from 0.00200 to 0.00184, saving model to weights-improvement-30.hdf5\n",
      "38/38 - 0s - loss: 0.0018 - val_loss: 0.4414\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: loss improved from 0.00184 to 0.00165, saving model to weights-improvement-31.hdf5\n",
      "38/38 - 0s - loss: 0.0016 - val_loss: 0.4460\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: loss improved from 0.00165 to 0.00155, saving model to weights-improvement-32.hdf5\n",
      "38/38 - 0s - loss: 0.0015 - val_loss: 0.4591\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: loss improved from 0.00155 to 0.00136, saving model to weights-improvement-33.hdf5\n",
      "38/38 - 0s - loss: 0.0014 - val_loss: 0.4585\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: loss improved from 0.00136 to 0.00126, saving model to weights-improvement-34.hdf5\n",
      "38/38 - 0s - loss: 0.0013 - val_loss: 0.4760\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: loss improved from 0.00126 to 0.00116, saving model to weights-improvement-35.hdf5\n",
      "38/38 - 0s - loss: 0.0012 - val_loss: 0.4652\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: loss improved from 0.00116 to 0.00105, saving model to weights-improvement-36.hdf5\n",
      "38/38 - 0s - loss: 0.0011 - val_loss: 0.4764\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: loss improved from 0.00105 to 0.00097, saving model to weights-improvement-37.hdf5\n",
      "38/38 - 0s - loss: 9.6853e-04 - val_loss: 0.4800\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: loss improved from 0.00097 to 0.00091, saving model to weights-improvement-38.hdf5\n",
      "38/38 - 0s - loss: 9.0958e-04 - val_loss: 0.4817\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: loss improved from 0.00091 to 0.00085, saving model to weights-improvement-39.hdf5\n",
      "38/38 - 0s - loss: 8.4796e-04 - val_loss: 0.4816\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: loss improved from 0.00085 to 0.00080, saving model to weights-improvement-40.hdf5\n",
      "38/38 - 0s - loss: 7.9767e-04 - val_loss: 0.4879\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: loss improved from 0.00080 to 0.00076, saving model to weights-improvement-41.hdf5\n",
      "38/38 - 0s - loss: 7.5504e-04 - val_loss: 0.4893\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: loss improved from 0.00076 to 0.00070, saving model to weights-improvement-42.hdf5\n",
      "38/38 - 0s - loss: 6.9767e-04 - val_loss: 0.4988\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: loss improved from 0.00070 to 0.00065, saving model to weights-improvement-43.hdf5\n",
      "38/38 - 0s - loss: 6.4663e-04 - val_loss: 0.5081\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: loss improved from 0.00065 to 0.00061, saving model to weights-improvement-44.hdf5\n",
      "38/38 - 0s - loss: 6.0938e-04 - val_loss: 0.5015\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: loss improved from 0.00061 to 0.00058, saving model to weights-improvement-45.hdf5\n",
      "38/38 - 0s - loss: 5.7727e-04 - val_loss: 0.5062\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: loss improved from 0.00058 to 0.00054, saving model to weights-improvement-46.hdf5\n",
      "38/38 - 0s - loss: 5.4343e-04 - val_loss: 0.5106\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: loss improved from 0.00054 to 0.00051, saving model to weights-improvement-47.hdf5\n",
      "38/38 - 0s - loss: 5.1446e-04 - val_loss: 0.5203\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: loss improved from 0.00051 to 0.00048, saving model to weights-improvement-48.hdf5\n",
      "38/38 - 0s - loss: 4.7876e-04 - val_loss: 0.5148\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: loss improved from 0.00048 to 0.00046, saving model to weights-improvement-49.hdf5\n",
      "38/38 - 0s - loss: 4.5836e-04 - val_loss: 0.5254\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: loss improved from 0.00046 to 0.00043, saving model to weights-improvement-50.hdf5\n",
      "38/38 - 0s - loss: 4.3406e-04 - val_loss: 0.5269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8ec1d17040>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_class_model = DNN_Multi_Classification_KS(input_dim)\n",
    "multi_class_model.fit(x_train,y_train,batch_size=batch_size,\n",
    "                      epochs=training_epochs,verbose=2,validation_split=0.1,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = multi_class_model.predict_classes(x_train)\n",
    "y_test_pred = multi_class_model.predict_classes(x_test)\n",
    "\n",
    "y_train_cls = np.argmax(y_train,axis=1)\n",
    "y_test_cls = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Classification Train Confusion matrix :\n",
      " [[125   0   0   0   0   0   0   0   0   0]\n",
      " [  0 129   1   0   0   0   0   0   0   2]\n",
      " [  0   1 129   0   0   0   0   0   0   0]\n",
      " [  0   0   0 129   0   0   0   0   0   0]\n",
      " [  0   1   0   0 119   0   0   0   0   1]\n",
      " [  0   0   0   0   0 116   0   0   0   0]\n",
      " [  0   0   0   0   0   0 127   0   1   0]\n",
      " [  0   0   0   0   0   0   0 124   0   0]\n",
      " [  0   0   0   0   0   0   0   0 131   0]\n",
      " [  0   0   0   0   0   0   0   0   0 121]]\n",
      "Multi Classification Test Confusion matrix :\n",
      " [[51  0  0  0  0  0  0  0  1  1]\n",
      " [ 0 43  1  0  2  0  0  0  2  2]\n",
      " [ 0  0 44  2  0  0  0  0  1  0]\n",
      " [ 0  0  2 50  0  1  0  0  1  0]\n",
      " [ 0  0  0  0 59  0  0  1  0  0]\n",
      " [ 0  0  0  0  1 63  1  0  0  1]\n",
      " [ 0  0  0  0  0  1 52  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 53  0  1]\n",
      " [ 1  2  1  1  0  1  0  0 36  1]\n",
      " [ 0  1  0  1  0  0  0  0  1 56]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Multi Classification Train Confusion matrix :\\n\",\n",
    "      confusion_matrix(y_train_cls,y_train_pred))\n",
    "print(\"Multi Classification Test Confusion matrix :\\n\",\n",
    "      confusion_matrix(y_test_cls,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Classification Train Accuracy :  0.9944\n",
      "Multi Classification Test Accuracy :  0.9389\n"
     ]
    }
   ],
   "source": [
    "print(\"Multi Classification Train Accuracy : \",\n",
    "      round(accuracy_score(y_train_cls,y_train_pred),4))\n",
    "print(\"Multi Classification Test Accuracy : \",\n",
    "      round(accuracy_score(y_test_cls,y_test_pred),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An Example of Binary Classification Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shovonsengupta/Desktop/Python/Notebook\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages/libraries\n",
    "import pandas as pd\n",
    "from numpy import expand_dims\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/shovonsengupta/Desktop/Python/Notebook/PayPal_all/'\n",
    "credit_data = pd.read_csv(data_path+\"credit_data.csv\")\n",
    "credit_data['class'] = credit_data['class']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1007, 21)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.707051\n",
       "1    0.292949\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data['class'].value_counts()/len(credit_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_stseca = pd.get_dummies(credit_data['Status_of_existing_checking_account'], prefix='status_exs_accnt')\n",
    "dummy_ch = pd.get_dummies(credit_data['Credit_history'], prefix='cred_hist')\n",
    "dummy_purpose = pd.get_dummies(credit_data['Purpose'], prefix='purpose')\n",
    "dummy_savacc = pd.get_dummies(credit_data['Savings_Account'], prefix='sav_acc')\n",
    "dummy_presc = pd.get_dummies(credit_data['Present_Employment_since'], prefix='pre_emp_snc')\n",
    "dummy_perssx = pd.get_dummies(credit_data['Personal_status_and_sex'], prefix='per_stat_sx')\n",
    "dummy_othdts = pd.get_dummies(credit_data['Other_debtors'], prefix='oth_debtors')\n",
    "dummy_property = pd.get_dummies(credit_data['Property'], prefix='property')\n",
    "dummy_othinstpln = pd.get_dummies(credit_data['Other_installment_plans'], prefix='oth_inst_pln')\n",
    "dummy_housing = pd.get_dummies(credit_data['Housing'], prefix='housing')\n",
    "dummy_job = pd.get_dummies(credit_data['Job'], prefix='job')\n",
    "dummy_telephn = pd.get_dummies(credit_data['Telephone'], prefix='telephn')\n",
    "dummy_forgnwrkr = pd.get_dummies(credit_data['Foreign_worker'], prefix='forgn_wrkr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_columns = ['Duration_in_month', 'Credit_amount', 'Installment_rate_in_percentage_of_disposable_income',\n",
    "                      'Present_residence_since', 'Age_in_years', 'Number_of_existing_credits_at_this_bank',\n",
    "                      'Number_of_People_being_liable_to_provide_maintenance_for']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_continuous = credit_data[continuous_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "credit_cont_scale = scaler.fit_transform(credit_continuous)\n",
    "credit_cont_scale_pd = pd.DataFrame(credit_cont_scale)\n",
    "credit_cont_scale_pd.columns = continuous_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration_in_month</th>\n",
       "      <th>Credit_amount</th>\n",
       "      <th>Installment_rate_in_percentage_of_disposable_income</th>\n",
       "      <th>Present_residence_since</th>\n",
       "      <th>Age_in_years</th>\n",
       "      <th>Number_of_existing_credits_at_this_bank</th>\n",
       "      <th>Number_of_People_being_liable_to_provide_maintenance_for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058554</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.363237</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117617</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.486270</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.294361</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Duration_in_month  Credit_amount  \\\n",
       "0           0.029412       0.058554   \n",
       "1           0.647059       0.363237   \n",
       "2           0.117647       0.117617   \n",
       "3           0.558824       0.486270   \n",
       "4           0.294118       0.294361   \n",
       "\n",
       "   Installment_rate_in_percentage_of_disposable_income  \\\n",
       "0                                           1.000000     \n",
       "1                                           0.333333     \n",
       "2                                           0.333333     \n",
       "3                                           0.333333     \n",
       "4                                           0.666667     \n",
       "\n",
       "   Present_residence_since  Age_in_years  \\\n",
       "0                 1.000000      0.857143   \n",
       "1                 0.333333      0.053571   \n",
       "2                 0.666667      0.535714   \n",
       "3                 1.000000      0.464286   \n",
       "4                 1.000000      0.607143   \n",
       "\n",
       "   Number_of_existing_credits_at_this_bank  \\\n",
       "0                                 0.333333   \n",
       "1                                 0.000000   \n",
       "2                                 0.000000   \n",
       "3                                 0.000000   \n",
       "4                                 0.333333   \n",
       "\n",
       "   Number_of_People_being_liable_to_provide_maintenance_for  \n",
       "0                                                0.0         \n",
       "1                                                0.0         \n",
       "2                                                1.0         \n",
       "3                                                1.0         \n",
       "4                                                1.0         "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_cont_scale_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all the variables\n",
    "credit_data_new = pd.concat([dummy_stseca, dummy_ch, dummy_purpose, dummy_savacc, dummy_presc, dummy_perssx,\n",
    "                             dummy_othdts, dummy_property, dummy_othinstpln, dummy_housing, dummy_job,\n",
    "                             dummy_telephn, dummy_forgnwrkr, credit_cont_scale_pd, credit_data['class']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to scale the continuous variables and combine for later processing\n",
    "df_x_train, df_x_test, y_train_inter, y_test_inter = train_test_split(credit_data_new.drop(['class'], axis=1),\n",
    "                                                    credit_data_new['class'],train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(df_x_train)\n",
    "x_test = np.array(df_x_test)\n",
    "y_train = expand_dims(y_train_inter, axis=1)\n",
    "y_test = expand_dims(y_test_inter, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704, 61)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN_Binary_Classification_KS(_input_dim):\n",
    "    # Layer 1\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10,input_shape=(_input_dim,)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Layer 2\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "    # Layer 3\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    adam_opt = Adam(lr=0.01)\n",
    "    # Model compilation\n",
    "    model.compile(loss='binary_crossentropy',optimizer=adam_opt)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "input_dim = 61\n",
    "training_epochs = 50\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "24/24 [==============================] - 0s 980us/step - loss: 0.6243\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5321\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4831\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4607\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4148\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3861\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3366\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3263\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3172\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2807\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 978us/step - loss: 0.2491\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2457\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2250\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 961us/step - loss: 0.2150\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 953us/step - loss: 0.2007\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1869\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1732\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1906\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 915us/step - loss: 0.1742\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1492\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1267\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1203\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1138\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1224\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.1260\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1223\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1296\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1116\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0849\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0766\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0737\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0642\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0649\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0600\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0595\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0526\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0511\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0508\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0450\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0420\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0390\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0434\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0450\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0402\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0528\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0779\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0738\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0695\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0526\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8eba026610>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_class_model = DNN_Binary_Classification_KS(input_dim)\n",
    "bin_class_model.fit(x_train,y_train,batch_size=batch_size,epochs=training_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = bin_class_model.predict_classes(x_train)\n",
    "y_test_pred = bin_class_model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classification Train Confusion matrix :\n",
      " [[495   6]\n",
      " [  6 197]]\n",
      "Binary Classification Test Confusion matrix :\n",
      " [[193  18]\n",
      " [ 32  60]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Binary Classification Train Confusion matrix :\\n\",\n",
    "      confusion_matrix(y_train,y_train_pred))\n",
    "print(\"Binary Classification Test Confusion matrix :\\n\",\n",
    "      confusion_matrix(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classification Train Accuracy :  0.983\n",
      "Binary Classification Test Accuracy :  0.835\n"
     ]
    }
   ],
   "source": [
    "print(\"Binary Classification Train Accuracy : \",\n",
    "      round(accuracy_score(y_train,y_train_pred),4))\n",
    "print(\"Binary Classification Test Accuracy : \",\n",
    "      round(accuracy_score(y_test,y_test_pred),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
